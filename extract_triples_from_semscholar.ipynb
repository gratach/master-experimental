{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from os import environ\n",
    "from pathlib import Path\n",
    "from json import loads, dumps\n",
    "environ[\"SEMSCHOLAR_KEY\"] = Path(\"~/.semscholarkey\").expanduser().read_text().strip()\n",
    "datapath = Path(\"../master-database-files/master-experimental/extract_triples_from_semscholar\")\n",
    "assert datapath.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def pause_until(timespan):\n",
    "    current_time = time.time()\n",
    "    if pause_until.last_time != None and current_time - pause_until.last_time < timespan:\n",
    "        time.sleep(timespan - (current_time - pause_until.last_time))\n",
    "    pause_until.last_time = time.time()\n",
    "\n",
    "# Initialize the last_time attribute\n",
    "pause_until.last_time = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ\n",
    "from pathlib import Path\n",
    "from json import loads, dumps\n",
    "from random import choice\n",
    "environ[\"OPENAI_API_KEY\"] = Path(\"~/.openaiapikey\").expanduser().read_text().strip()\n",
    "from openai import OpenAI\n",
    "from random import randint\n",
    "\n",
    "openaiClient = OpenAI()\n",
    "def gpt_3_5_turbo_completion(query, temperature = 1):\n",
    "    answer = openaiClient.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": query\n",
    "            }\n",
    "        ],\n",
    "        temperature = temperature,\n",
    "        seed = randint(0, 1000000)\n",
    "    )\n",
    "    return answer.choices[0].message.content\n",
    "\n",
    "def gpt_4_turbo_completion(query, temperature = 1):\n",
    "    answer = openaiClient.chat.completions.create(\n",
    "        model=\"gpt-4-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": query\n",
    "            }\n",
    "        ],\n",
    "        temperature = temperature,\n",
    "        seed = randint(0, 1000000)\n",
    "    )\n",
    "    return answer.choices[0].message.content\n",
    "\n",
    "def tryRecieveAnswer(query, completionFunction = gpt_3_5_turbo_completion, answerConversion = lambda x: True, maxTries = 10, temperature = 1):\n",
    "    tryNumber = 0\n",
    "    while tryNumber < maxTries:\n",
    "        answer = completionFunction(query, temperature)\n",
    "        try:\n",
    "            answer = answerConversion(answer)\n",
    "            return (answer, True)\n",
    "        except:\n",
    "            pass\n",
    "        tryNumber += 1\n",
    "    print(f\"Failed to recieve answer for query: {query}\")\n",
    "    print(f\"Answer: {answer}\")\n",
    "    return (None, False)\n",
    "\n",
    "def listAnswerConversion(answer):\n",
    "    result = loads(answer)\n",
    "    assert isinstance(result, list)\n",
    "    for item in result:\n",
    "        assert isinstance(item, str)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractTripleFromAbstract(abstract, title, subject):\n",
    "    query = f\"\"\"\n",
    "Semantic triples such as [\"Star\", \"emits\", \"Light\"] and [\"Rocket\", \"can bring cargo to\", \"Space\"] consists of a subject, a predicate, and an object.\n",
    "Please extract a triple from the following abstract that contains the subject \"{subject}\":\n",
    "\n",
    "Abstract of the paper \"{title}\":\n",
    "{abstract}\n",
    "\n",
    "Return nothing but the triple in the format [\"subject\", \"predicate\", \"object\"].\n",
    "\"\"\"\n",
    "    def answerConversion(answer):\n",
    "        ret = loads(answer)\n",
    "        assert isinstance(ret, list)\n",
    "        assert len(ret) == 3\n",
    "        for item in ret:\n",
    "            assert isinstance(item, str)\n",
    "        return ret\n",
    "    answer, success = tryRecieveAnswer(query, answerConversion = answerConversion)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['machine learning approaches', 'rely on', 'low-level input']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractTripleFromAbstract(\"\"\"Based on the established task of identifying boosted, hadronically decaying top\n",
    "quarks, we compare a wide range of modern machine learning approaches. Unlike\n",
    "most established methods they rely on low-level input, for instance calorimeter\n",
    "output. While their network architectures are vastly different, their performance\n",
    "is comparatively similar. In general, we find that these new approaches are ex-\n",
    "tremely powerful and great fun.\"\"\", \"machine learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractTriplesFromSemanticScholarAbstracts(term, outputFilePath, numberOfTriples = 1):\n",
    "    outputFilePath = Path(outputFilePath)\n",
    "    if outputFilePath.exists():\n",
    "        raise Exception(f\"Output file {outputFilePath} already exists!\")\n",
    "    with outputFilePath.open(\"w\") as outputFile:\n",
    "        outputFile.write(\"[\")\n",
    "        triples = []\n",
    "        papers = []\n",
    "        searchOffset = 0\n",
    "        searchStep = 100\n",
    "        while len(triples) < numberOfTriples:\n",
    "            if len(papers) == 0:\n",
    "                pause_until(1)\n",
    "                req = requests.get(f\"https://api.semanticscholar.org/graph/v1/paper/search?query={term}&offset={searchOffset}&limit={searchStep}&fields=abstract,title\", headers = {\"x-api-key\": environ[\"SEMSCHOLAR_KEY\"]})\n",
    "                papers = loads(req.text)[\"data\"]\n",
    "                searchOffset += searchStep\n",
    "                if len(papers) == 0:\n",
    "                    break\n",
    "            paper = papers.pop(0)\n",
    "            abstract = paper[\"abstract\"]\n",
    "            title = paper[\"title\"]\n",
    "            if abstract == None:\n",
    "                continue\n",
    "            paperId = paper[\"paperId\"]\n",
    "            triple = extractTripleFromAbstract(abstract, title, term)\n",
    "            outputFile.write(f\"    [{dumps(triple)}, {dumps(paperId)}]{',' if len(triples) < numberOfTriples - 1 else ''}\\n\")\n",
    "            outputFile.flush()\n",
    "            triples.append(triple)\n",
    "        outputFile.write(\"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractTriplesFromSemanticScholarAbstracts(\"electron\", datapath / \"electron_triples.json\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
